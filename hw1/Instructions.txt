For this homework, you will implement classification trees and random forests that support numeric input variables and a binary target variable.

[PART 1]

You will implement classification trees and random forests as classes (Tree, RandomForest) that provide a method build, which returns the model as an object, whose predict method returns the predicted target class of given input samples (see attached code for usage examples):

Tree - a flexible classification tree with the following attributes: (1) rand, a random generator, for reproducibility, of type random.Random; (2) get_candidate_columns, a function that returns a list of column indices considered for a split (needed for the random forests); and (3) min_samples, the minimum number of samples, where a node is still split further. Use the _gini impurity to select the best splits.

RandomForest, with attributes: (1) rand, a random generator; (2) n: number of
bootstrap samples. The RandomForest should use an instance of Tree internally. Build full trees (min_samples=2). For each split, consider random (square root of the number of input variables) variables.

Test your implementation with unittests that focus on the critical or hard parts and edge cases. Combine all tests in a class named MyTests.

Apply the developed methods to the TKI resistance FTIR spectral data set. Always use the -train data as the training set and the -test as the testing set. Do the following:

In function hw_tree_full, build a tree with min_samples=2. Return misclassification rates and standard errors when using training and testing data as test sets.

In function hw_randomforest, use random forests with n=100 trees with min_samples=2. Return misclassification rates and standard errors when using training and testing data as test sets.

As a rough guideline, building the full tree on this data set should take less than 10 seconds - more shows inefficiencies in the implementation.

This assignment requires that you compute standard errors to quantify the uncertainty of the misclassification rates. Here, we only require an estimate of the uncertainty stemming from a particular test set measurement. Therefore, there is no need to rebuild models when computing standard errors for this assignment.

In the report:

Explain how you quantify the uncertainty of your estimates.

Show misclassification rates (and their uncertainties) from hw_tree_full.

Show misclassification rates (and their uncertainties) from hw_randomforest.

Plot misclassification rates versus the number of trees n.

[PART 2, grades 7-8]

Implement permutation-based variable importance. Refer to the "Variable Importance" section from "The Elements of Statistical Learning"; implement it as method importance() of the random forest model.

Computing random forest variable importance for all variables should not be a slow operation. For me, it is much faster than building the random forest.

In the report, plot variable importance for the given data set for an RF with n=100 trees. Note that variables have a particular ordering for this kind of data, so keep the variable order when plotting. For comparison, also show variables from the roots of 100 non-random trees on sensibly randomized data on the same plot.

[PART 3, grades 9-10]

Extend random forests variable importance to combinations of 3 variables (in method importance3()). Apply the original variable importance and your extended version on TKI resistance data (use forest with n=1000 trees). Compare (and report) the performance of classification trees built on the best 3 variables for both variable importance variants.

Assume that we have a pre-built forest, but no data, so we can not use variable importance as implemented in the previous parts of the assignment. Implement an algorithm that picks the best combination of 3 variables for building a single classification tree by exploring the structure of trees in the forests (method importance3_structure()). In the report (and during defense) you must convince your assistant why your solution should work well; be brief.

[GENERAL NOTES] Your code must be Python 3.12 compatible and must conform to the unit tests from test_hw_tree.py; see tests for the precise interface. In your code, execute anything only under if __name__ == "__main__". Keep the code simple nad efficient. Do not explicit multithreading/multiprocessing for speed.

You need to write the crux of the solution yourself, but feel free to use libraries for data reading and management (numpy, pandas) and drawing (matplotlib). Submit your code in a single file named hw_tree.py.

Submit a report in a single .pdf file (max two pages). Structure it so your assistant can quickly find the parts he explicitly requested.
